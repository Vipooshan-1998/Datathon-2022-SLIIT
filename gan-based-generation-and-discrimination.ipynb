{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnX0atWNppA3"
   },
   "source": [
    "<h2 align=center>Generate Synthetic Images with DCGANs in Keras</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AY-qM-4swLUb"
   },
   "source": [
    "## Task 1: Project Overview and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bhqrEV6hkFC3",
    "outputId": "18f64663-c0ea-4790-fece-446ea2269793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# import plot_utils\n",
    "\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utility function to show the 2images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRT9FVAdwUDP"
   },
   "source": [
    "## Task 2: Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(r'D:\\datathon 2022 dataset\\Data_Split - Mp vs Others\\train')\n",
    "test_dir = os.path.join(r'D:\\datathon 2022 dataset\\Data_Split - Mp vs Others\\val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def image_generator(train_parent_directory, test_parent_directory):\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(train_parent_directory,\n",
    "                                  target_size = (224, 224),\n",
    "                                  batch_size = 214,\n",
    "                                  class_mode = 'categorical',\n",
    "                                  subset='training')\n",
    " \n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(test_parent_directory,\n",
    "                                 target_size=(224, 224),\n",
    "                                 batch_size = 37,\n",
    "                                 class_mode = 'categorical')    \n",
    "    \n",
    "    return train_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, test_generator = image_generator(train_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "for j in range(len(train_generator)):    \n",
    "    for m in train_generator[j][0]: \n",
    "        X_train.append(m)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9g2aKYa9kG1Q",
    "outputId": "cdbb6ae5-4c62-49c1-9cdf-44297bac0e29"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFEwYL2HJ5no",
    "outputId": "5705c4c1-c8b4-487c-e82a-4402a41b8589"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B6mV5YZw_p7"
   },
   "source": [
    "## Task 3: Create Batches of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqwFFyrFkG7b"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5qOeWQDxp7A"
   },
   "source": [
    "## Task 4: Build the Generator Network for DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4qXzYgEs4RR"
   },
   "source": [
    "![GAN](https://github.com/blurred-machine/Generate-Synthetic-Images-with-DCGANs-in-Keras/blob/master/dcgan.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_Pz36D9T3dp"
   },
   "outputs": [],
   "source": [
    "num_features = 100\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(7 * 7 * 256, input_shape=[num_features]),\n",
    "    keras.layers.Reshape([7, 7, 256]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(128, (5,5), (1,1), padding=\"same\", activation=\"selu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(64, (5,5), (2,2), padding=\"same\", activation=\"selu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(1, (5,5), (2,2), padding=\"same\", activation=\"tanh\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMihRHcHT3hU",
    "outputId": "434178f1-ec98-4cda-8d9b-12337a36d1d5"
   },
   "outputs": [],
   "source": [
    "noise = tf.random.normal(shape=[1, num_features])\n",
    "generated_images = generator(noise, training=False)\n",
    "show(generated_images, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMUiBeXhVMWf"
   },
   "source": [
    "## Tak 5: Build the Discriminator Network for DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect and init the TPU\n",
    "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "# tf.config.experimental_connect_to_cluster(tpu)\n",
    "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "# instantiating the model in the strategy scope creates the model on the TPU\n",
    "# with tpu_strategy.scope():\n",
    "#     model = tf.keras.Sequential( … ) # define your model normally\n",
    "#     model.compile( … )\n",
    "\n",
    "# train model normally\n",
    "# model.fit(training_dataset, epochs=EPOCHS, steps_per_epoch=…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNoA-K62kHEI"
   },
   "outputs": [],
   "source": [
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, (5,5), (2,2), padding=\"same\", input_shape=[28, 28, 1]),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Conv2D(128, (5,5), (2,2), padding=\"same\"),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Conv2D(256, (5,5), (1,1), padding=\"same\"),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8NRrD1WUYeb",
    "outputId": "6ab66e9f-dade-4519-9c72-18c579c2f0c8"
   },
   "outputs": [],
   "source": [
    "decision = discriminator(generated_images)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjkSFNGGVT4I"
   },
   "source": [
    "## Task 6: Compile the Deep Convolutional Generative Adversarial Network (DCGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOpPAq_ckHHz"
   },
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "discriminator.trainable = False\n",
    "gan = keras.models.Sequential([generator, discriminator])\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKJzwn3ExORM"
   },
   "source": [
    "## Task 7: Define Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ic76LI4xfGPD"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from tqdm import tqdm\n",
    "seed = tf.random.normal(shape=[batch_size, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RX-t-8XmlemS"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_dcgan(gan, dataset, batch_size, num_features, epochs=5):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, epochs))\n",
    "        for X_batch in dataset:\n",
    "            noise = tf.random.normal(shape=[batch_size, num_features])\n",
    "            generated_images = generator(noise)\n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "            noise = tf.random.normal(shape=[batch_size, num_features])\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "            # Produce images for the GIF as we go\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n",
    "        \n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDbSHgN5gVT0"
   },
   "outputs": [],
   "source": [
    "## Source https://www.tensorflow.org/tutorials/generative/dcgan#create_a_gif\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='binary')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ehb_zChMyMms"
   },
   "source": [
    "## Task 8: Train DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIttFRtEkHKA"
   },
   "outputs": [],
   "source": [
    "x_train_dcgan = x_train.reshape(-1, 28, 28, 1) * 2. - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EK6oZ_3ekHNP"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_train_dcgan)\n",
    "dataset = dataset.shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8VXDKHikHO0",
    "outputId": "5768d21f-82ec-4ed4-dacb-cf14621ba379"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_dcgan(gan, dataset, batch_size, num_features, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gToylYoE6Rw4"
   },
   "source": [
    "## Task 9: Generate Synthetic Images with DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lbr9e1gvkHVW",
    "outputId": "35a2562c-e2b4-4e08-e463-4459c91bd329"
   },
   "outputs": [],
   "source": [
    "noise = tf.random.normal(shape=[batch_size, num_features])\n",
    "generated_images = generator(noise)\n",
    "show(generated_images, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Orl5VXTbnQ9"
   },
   "outputs": [],
   "source": [
    "## Source: https://www.tensorflow.org/tutorials/generative/dcgan#create_a_gif\n",
    "import imageio\n",
    "import glob\n",
    "\n",
    "anim_file = 'dcgan_anim.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        frame = 2*(i)\n",
    "        if round(frame) > round(last):\n",
    "            last = frame\n",
    "        else:\n",
    "            continue\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "\n",
    "    #import IPython\n",
    "    #display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://github.com/blurred-machine/Generate-Synthetic-Images-with-DCGANs-in-Keras/blob/master/dcgan_anim.gif?raw=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
